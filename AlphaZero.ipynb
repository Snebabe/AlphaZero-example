{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687111dc-c984-43fd-9821-45515141d498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "2.6.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# ! python.exe -m pip install --upgrade pip\n",
    "# ! pip install numpy\n",
    "# ! pip install torch\n",
    "# ! pip install tqdm\n",
    "# ! pip install ipywidgets --upgrade\n",
    "# ! pip install jupyter\n",
    "# ! pip install --upgrade notebook jupyterlab ipywidgets\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0091477c-0530-49eb-9ce5-f861807bb771",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ConnectFour:\n",
    "    def __init__(self):\n",
    "        self.row_count = 6\n",
    "        self.column_count = 7\n",
    "        self.action_size = self.column_count\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        return np.zeros((self.row_count, self.column_count))\n",
    "\n",
    "    def get_next_state(self, state, action: int, player):\n",
    "        for row in reversed(range(self.row_count)):\n",
    "            if state[row, action] == 0:\n",
    "                state[row, action] = player\n",
    "                return state\n",
    "\n",
    "        # should not happen\n",
    "        return state\n",
    "\n",
    "    def get_valid_moves(self, state):\n",
    "        return (state[0] == 0).astype(np.uint8)\n",
    "\n",
    "    def check_win(self, state, action): \n",
    "        if action == None: return False\n",
    "        # Get player\n",
    "        for row in range(self.row_count):\n",
    "            if state[row][action] != 0:\n",
    "                player = state[row][action]\n",
    "                break\n",
    "        for row in range(self.row_count):\n",
    "            for col in range(self.column_count):\n",
    "                if self.check_direction(row, col, 1, 0, player, state) or \\\n",
    "                   self.check_direction(row, col, 0, 1, player, state) or \\\n",
    "                   self.check_direction(row, col, 1, 1, player, state) or \\\n",
    "                   self.check_direction(row, col, 1, -1, player, state):\n",
    "                    return True\n",
    "\n",
    "    def check_direction(self, row, col, drow, dcol, player, state):\n",
    "        count = 0\n",
    "        for _ in range(4):\n",
    "            if 0 <= row < self.row_count and 0 <= col < self.column_count and state[row][col] == player:\n",
    "                count += 1\n",
    "                if count >= 4:\n",
    "                    return True\n",
    "            else:\n",
    "                break\n",
    "            row += drow\n",
    "            col += dcol\n",
    "        return False\n",
    "\n",
    "    def get_value_and_terminated(self, state, action):\n",
    "        if self.check_win(state, action):\n",
    "            return 1, True\n",
    "        if np.sum(self.get_valid_moves(state)) == 0:\n",
    "            return 0, True\n",
    "        return 0, False\n",
    "\n",
    "    def get_opponent(self, player):\n",
    "        return -player\n",
    "\n",
    "    def get_opponent_value(self, value):\n",
    "        return -value\n",
    "\n",
    "    def change_perspective(self, state, player):\n",
    "        return state * player\n",
    "    \n",
    "    def get_encoded_state(self, state):\n",
    "        # Encode it for the AI\n",
    "        # Look at the architecture notes in docs\n",
    "        # We want three input states, one for each player and one with empty cells\n",
    "        encoded_state = np.stack(\n",
    "            (state == -1, state == 0, state == 1)\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        return encoded_state\n",
    "    \n",
    "    def print_state(self, state):\n",
    "        symbols = {0: \"-\", 1: \"X\", -1: \"O\"}\n",
    "        display = \"\\n\".join(\" \".join(symbols[cell] for cell in row) for row in state)\n",
    "        print(display)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bbc4bf-a805-4871-be18-7cccf370f59b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Start by creating our game, which AlphaZero will play.\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.row_count = 3\n",
    "        self.column_count = 3\n",
    "        # action size is the amount of possible actions (moves)\n",
    "        self.action_size = self.row_count * self.column_count\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        # new board = board full of zeros\n",
    "        return np.zeros((self.column_count, self.row_count))\n",
    "\n",
    "    def get_next_state(self, state, action: int, player):\n",
    "        \"\"\"\n",
    "        state = board (2D array)\n",
    "        action = 0-8 which cell to place move\n",
    "        player = player\n",
    "        \"\"\"\n",
    "        row = action // self.column_count\n",
    "        column = action % self.column_count\n",
    "        state[row, column] = player\n",
    "        return state\n",
    "\n",
    "    def get_valid_moves(self, state):\n",
    "        # state.reshape() reshapes the matrix, in our case from 3x3 into something else\n",
    "        # the -1 in state.reshape(-1) tells np to reshape automatically\n",
    "        # in our case our 3x3 will become 1x9, the output is the new np matrix\n",
    "        # looking like this: ([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "        # by doing == 0 we get an output array like this:\n",
    "        # np.array([True, True, True, True, True, True, True, True, True])\n",
    "        # the last code, astype, tells np to convert the values into unsigned integers, making the array:\n",
    "        # np.array([1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "        return (state.reshape(-1) == 0).astype(np.uint8)\n",
    "\n",
    "    def check_win(self, state, action):\n",
    "        if action == None:\n",
    "            return False\n",
    "            \n",
    "        row = action // self.column_count\n",
    "        column = action % self.column_count\n",
    "        player = state[row, column]\n",
    "\n",
    "        return (\n",
    "            # Checks for rows, assume player is an integer\n",
    "            np.sum(state[row, :]) == player * self.column_count\n",
    "            or np.sum(state[:, column]) == player * self.row_count\n",
    "            # Checks for diagonals, \n",
    "            or np.sum(np.diag(state)) == player * self.row_count\n",
    "            or np.sum(np.diag(np.flip(state, axis=0))) == player * self.row_count\n",
    "        )\n",
    "\n",
    "    def get_value_and_terminated(self, state, action):\n",
    "        if self.check_win(state, action):\n",
    "            return 1, True\n",
    "        if np.sum(self.get_valid_moves(state)) == 0:\n",
    "            return 0, True\n",
    "        return 0, False\n",
    "\n",
    "    def get_opponent(self, player):\n",
    "        return -player\n",
    "\n",
    "    def get_opponent_value(self, value):\n",
    "        return -value\n",
    "\n",
    "    def change_perspective(self, state, player):\n",
    "        return state * player\n",
    "    \n",
    "    def get_encoded_state(self, state):\n",
    "        # Encode it for the AI\n",
    "        # Look at the architecture notes in docs\n",
    "        # We want three input states, one for each player and one with empty cells\n",
    "        encoded_state = np.stack(\n",
    "            (state == -1, state == 0, state == 1)\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        return encoded_state\n",
    "\n",
    "    def print_state(self, state):\n",
    "        symbols = {0: \"-\", 1: \"X\", -1: \"O\"}\n",
    "        display = \"\\n\".join(\" \".join(symbols[cell] for cell in row) for row in state)\n",
    "        print(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b2b0d4-8404-4ad1-a62b-1a2a8e67eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal MCTS\n",
    "\n",
    "# Here, the node will never know of the player\n",
    "# Instead, the rest of the code is programmed so that the state of the board\n",
    "# will always be from the nodes perspective (i.e. flipped, or inverted might be a better word)\n",
    "# For the node, the player is always player 1.\n",
    "# Logic should be easier, and also valid for 1 player games\n",
    "class Node:\n",
    "    def __init__(self, game, args, state, parent=None, action_taken=None, prior=0):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action_taken = action_taken\n",
    "        # probability by policy vector from parent, used in expansion \n",
    "        self.prior = prior\n",
    "\n",
    "        self.children = []\n",
    "\n",
    "        # Not needed with CNN, we expand all everytime\n",
    "        # self.expandable_moves = game.get_valid_moves(state)\n",
    "\n",
    "        self.visit_count = 0\n",
    "        self.value_sum = 0\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        # OLD, with CNN all will be expanded at once\n",
    "        # return np.sum(self.expandable_moves) == 0 and len(self.children) > 0\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def select(self):\n",
    "        best_child = None\n",
    "        best_ucb = -np.inf\n",
    "\n",
    "        for child in self.children:\n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb:\n",
    "                best_child = child\n",
    "                best_ucb = ucb\n",
    "\n",
    "        return best_child\n",
    "\n",
    "    def get_ucb(self, child):\n",
    "        if child.visit_count == 0:\n",
    "            q_value = 0\n",
    "        else:\n",
    "            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n",
    "        return q_value + self.args['C'] * child.prior * (math.sqrt(self.visit_count)/(child.visit_count + 1))\n",
    "\n",
    "    def expand(self, policy):\n",
    "        for action, prob in enumerate(policy):\n",
    "            if prob > 0:\n",
    "                child_state = self.state.copy()\n",
    "                child_state = self.game.get_next_state(child_state, action, 1)\n",
    "                child_state = self.game.change_perspective(child_state, player=-1)\n",
    "\n",
    "                child = Node(self.game, self.args, child_state, self, action, prob)\n",
    "                self.children.append(child)\n",
    "\n",
    "    def backpropagate(self, value):\n",
    "        self.value_sum += value\n",
    "        self.visit_count += 1\n",
    "\n",
    "        # flip player\n",
    "        value = self.game.get_opponent_value(value)\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value)\n",
    "        \n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game, args, model):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "\n",
    "    # decorator as we don't want to store gradients\n",
    "    # don't know why\n",
    "    @torch.no_grad()\n",
    "    def search(self, state):\n",
    "        # define root \n",
    "        root = Node(self.game, self.args, state)\n",
    "        for search in range(self.args['num_searches']):\n",
    "            node = root\n",
    "            # selection\n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select()\n",
    "\n",
    "            # The action taken here will be from the opponent,\n",
    "            # Because of that, we take the negative value\n",
    "            # That is, the value seen from our node\n",
    "            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
    "            value = self.game.get_opponent_value(value)\n",
    "\n",
    "            if not is_terminal:\n",
    "                policy, value = self.model(\n",
    "                    torch.tensor(self.game.get_encoded_state(node.state)).unsqueeze(0)\n",
    "                )\n",
    "                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
    "                valid_moves = self.game.get_valid_moves(node.state)\n",
    "                # mask out invalid moves, \n",
    "                policy *= valid_moves\n",
    "                # normalize, \n",
    "                policy /= np.sum(policy)\n",
    "\n",
    "                # .item() on tensor with 1 float = you get the float\n",
    "                # this value replaces the simulation part\n",
    "                value = value.item()\n",
    "\n",
    "                # expansion\n",
    "                node.expand(policy)\n",
    "            # backpropagation\n",
    "            node.backpropagate(value)\n",
    "        \n",
    "        # return visit_counts\n",
    "        action_probs = np.zeros(self.game.action_size)\n",
    "        for child in root.children:\n",
    "            action_probs[child.action_taken] = child.visit_count\n",
    "        # Turn into probabilities, i.e. we want values in [0, 1].\n",
    "        # In this MCTS, the node with the most amount of visits \n",
    "        # is deemed the most promising move\n",
    "        action_probs /= np.sum(action_probs)\n",
    "        return action_probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cded231",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class AlphaZero:\n",
    "  def __init__(self, model, optimizer, game, args):\n",
    "    self.model = model\n",
    "    self.optimizer = optimizer\n",
    "    self.game = game\n",
    "    self.args = args\n",
    "    self.mcts = MCTS(game, args, model)\n",
    "\n",
    "  def selfPlay(self):\n",
    "    memory = []\n",
    "    player = 1\n",
    "    state = self.game.get_initial_state()\n",
    "\n",
    "    while True: \n",
    "      # remember, we want to search from player 1 perspective\n",
    "      neutral_state = self.game.change_perspective(state, player)\n",
    "      action_probs = self.mcts.search(neutral_state)\n",
    "\n",
    "      memory.append((neutral_state, action_probs, player))\n",
    "\n",
    "      action = np.random.choice(self.game.action_size, p=action_probs)\n",
    "\n",
    "      state = self.game.get_next_state(state, action, player)\n",
    "\n",
    "      value, is_terminal = self.game.get_value_and_terminated(state, action)\n",
    "\n",
    "      if is_terminal:\n",
    "        returnMemory = []\n",
    "        for hist_neutral_state, hist_action_probs, hist_player in memory:\n",
    "          hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
    "          returnMemory.append((\n",
    "            self.game.get_encoded_state(hist_neutral_state),\n",
    "            hist_action_probs,\n",
    "            hist_outcome\n",
    "          ))\n",
    "        return returnMemory\n",
    "    \n",
    "      player = self.game.get_opponent(player)\n",
    "\n",
    "  def train(self, memory):\n",
    "      random.shuffle(memory)\n",
    "      for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
    "          sample = memory[batchIdx:min(len(memory)-1, batchIdx + self.args['batch_size'])]\n",
    "          # Transpose sample \n",
    "          state, policy_targets, value_targets = zip(*sample)\n",
    "\n",
    "          state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
    "\n",
    "          state = torch.tensor(state, dtype=torch.float32)\n",
    "          policy_targets = torch.tensor(policy_targets, dtype=torch.float32)\n",
    "          value_targets = torch.tensor(value_targets, dtype=torch.float32)\n",
    "\n",
    "          out_policy, out_value = self.model(state)\n",
    "\n",
    "          policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
    "          value_loss = F.mse_loss(out_value, value_targets)\n",
    "          loss = policy_loss + value_loss\n",
    "\n",
    "          self.optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()          \n",
    "\n",
    "  def learn(self):\n",
    "    for iteration in range(self.args['num_iterations']):\n",
    "      memory = []\n",
    "\n",
    "      self.model.eval()\n",
    "      # trange = range() but with progress bars\n",
    "      for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']):\n",
    "        memory += self.selfPlay()\n",
    "\n",
    "      self.model.train()\n",
    "      for epoch in trange(self.args['num_epochs']):\n",
    "        self.train(memory)\n",
    "\n",
    "      torch.save(self.model.state_dict(), f\"model_{iteration}.pt\")\n",
    "      torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb48af7-f573-429b-ae49-ccf13778f6ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, game, num_resBlocks, num_hidden):\n",
    "        super().__init__()\n",
    "        self.startBlock = nn.Sequential(\n",
    "            # we can use kernel = 3 because we use padding = 1, \n",
    "            # so image will still be 3x3 (if you want to look at it like an image)\n",
    "            nn.Conv2d(3, num_hidden, kernel_size=3, padding=1),\n",
    "            # increase training speed\n",
    "            nn.BatchNorm2d(num_hidden),\n",
    "            # turn negatives to 0s, faster and safer to train\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.backBone = nn.ModuleList(\n",
    "            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n",
    "        )\n",
    "\n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            # this is the policy vector\n",
    "            # it should output the size of possible moves\n",
    "            # I think, why not just use len(game.get_valid_moves(state)), idk\n",
    "            # jag kom på varför\n",
    "            nn.Linear(32 * game.row_count * game.column_count, game.action_size)\n",
    "        )\n",
    "\n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, 3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * game.row_count * game.column_count, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.startBlock(x)\n",
    "        for resBlock in self.backBone:\n",
    "            x = resBlock(x)\n",
    "        policy = self.policyHead(x)\n",
    "        value = self.valueHead(x)\n",
    "        return policy, value\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
    "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlphaZero testing\n",
    "\n",
    "game = ConnectFour()\n",
    "\n",
    "model = ResNet(game, 4, 64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "try:\n",
    "    model.load_state_dict(torch.load('model_2.pt'))\n",
    "except FileNotFoundError:\n",
    "    print(\"Training from scratch\")\n",
    "    \n",
    "args = {\n",
    "  'C': 2,\n",
    "  'num_searches': 80,\n",
    "  'num_iterations': 8,\n",
    "  'num_selfPlay_iterations': 500,\n",
    "  'num_epochs': 4,\n",
    "  'batch_size': 64\n",
    "}\n",
    "\n",
    "alphaZero = AlphaZero(model, optimizer, game, args)\n",
    "alphaZero.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d707d0e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08199262619018555\n",
      "[0.0074585  0.05518941 0.22101723 0.3334862  0.08377649 0.20687835\n",
      " 0.09219384]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.  0.]]\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 0., 0., 1., 1., 1.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 1., 0., 0., 0., 0.]]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CNN testing\n",
    "# ! pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tictactoe = ConnectFour()\n",
    "\n",
    "state = tictactoe.get_initial_state()\n",
    "state = tictactoe.get_next_state(state, 2, 1)\n",
    "state = tictactoe.get_next_state(state, 3, -1)\n",
    "\n",
    "encoded_state = tictactoe.get_encoded_state(state)\n",
    "\n",
    "# no clue vad tensor, array av arrays?\n",
    "# typ för att representera en nod och deras inkommande weights\n",
    "# Because one state, and not a batch, we need to unsqueeze (ingen aning)\n",
    "tensor_state = torch.tensor(encoded_state).unsqueeze(0)\n",
    "\n",
    "model = ResNet(tictactoe, 4, 64)\n",
    "# Nu är den tränad, vamos\n",
    "model.load_state_dict(torch.load('model_2.pt'))\n",
    "model.eval()\n",
    "\n",
    "policy, value = model(tensor_state)\n",
    "value = value.item()\n",
    "# ingen aning\n",
    "policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "print(value)\n",
    "print(policy)\n",
    "print(state)\n",
    "print(tensor_state)\n",
    "\n",
    "plt.bar(range(tictactoe.action_size), policy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25eaedb9-7579-4ccb-b35e-2e461c22a388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "valid moves: [0, 1, 2, 3, 4, 5, 6]\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - X - - -\n",
      "Thinking...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - - - - -\n",
      "- - - X - O -\n",
      "valid moves: [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m valid_moves \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mget_valid_moves(state)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid moves:\u001b[39m\u001b[38;5;124m\"\u001b[39m, [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(game\u001b[38;5;241m.\u001b[39maction_size) \u001b[38;5;28;01mif\u001b[39;00m valid_moves[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 25\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mplayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_moves[action] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction not valid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "### CNN and MCTS\n",
    "\n",
    "game = ConnectFour()\n",
    "player = 1\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 4000\n",
    "}\n",
    "\n",
    "model = ResNet(game, 4, 64)\n",
    "model.load_state_dict(torch.load('model_3.pt'))\n",
    "model.eval()\n",
    "\n",
    "mcts = MCTS(game, args, model)\n",
    "\n",
    "state = game.get_initial_state()\n",
    "\n",
    "while True:\n",
    "    game.print_state(state)\n",
    "\n",
    "    if player == 1:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        print(\"valid moves:\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
    "        action = int(input(f\"{player}:\"))\n",
    "    \n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not valid\")\n",
    "            continue\n",
    "    else:\n",
    "        print(\"Thinking...\")\n",
    "        neutral_state = game.change_perspective(state, player)\n",
    "        policy = mcts.search(state)\n",
    "        # Utan MCTS, glömde av att man kör MCTS också\n",
    "        # encoded_state = game.get_encoded_state(neutral_state)\n",
    "        # tensor_state = torch.tensor(encoded_state).unsqueeze(0)\n",
    "        # policy, _ = model(tensor_state)\n",
    "        # policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
    "        plt.bar(range(game.action_size), policy)\n",
    "        plt.show()\n",
    "        action = np.argmax(policy)\n",
    "    \n",
    "    state = game.get_next_state(state, action, player)\n",
    "\n",
    "    value, is_terminal = game.get_value_and_terminated(state, action)\n",
    "\n",
    "    if is_terminal:\n",
    "        game.print_state(state)\n",
    "        if value == 1:\n",
    "            token = \"X\" if player == 1 else \"O\"\n",
    "            print(token, \"won\")\n",
    "        else: \n",
    "            print(\"draw\")\n",
    "        break\n",
    "\n",
    "    player = game.get_opponent(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f389d9-004d-4ef4-9bde-2b25f0541e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
